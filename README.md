
ASSIGNMENT SUBMITTED IN FULFILMENT OF THE REQUIREMENTS FOR THE ENTERPRISE DATA SCIENCE TRAINING PROGRAMME BY ADAX

The project aims to detect the existence of toxic comments in a given text. This project is developed using R. The training dataset was obtained from Kaggle.
(https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

The folder contains:
1) codes.R -> the main R script to run the model

2) assignment.Rmd -> A R Markdown presentation that describes how the model works

3) Images folder -> to store all relevant images

4) Toxic Comment Classification Challenge Python codes.txt 
-> a model (in Python) that uses tfidf Vectorizer and Multinomial Naive Bayes Classifier. 
